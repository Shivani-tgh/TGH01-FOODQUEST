{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c05d4d8-a284-4bd7-9e4f-1ba360afb69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.dropdown(\n",
    "    name=\"environment\",\n",
    "    defaultValue=\"fq_dev\",\n",
    "    choices=[\"fq_dev\", \"fq_test\", \"fq_prod\"],\n",
    "    label=\"Select environment\"\n",
    ")\n",
    "\n",
    "dbutils.widgets.combobox(\n",
    "    name=\"source\",\n",
    "    defaultValue=\"foodquest_sharepoint\",\n",
    "    choices=[\"posist\", \"netsuite\", \"other\",\"excel_sheet\",\"foodquest_sharepoint\"],\n",
    "    label=\"Source\"\n",
    ")\n",
    "\n",
    "dbutils.widgets.combobox(\n",
    "    name=\"domain\",\n",
    "    defaultValue=\"hr_workforce\",\n",
    "    choices=[\"discount\", \"sales\", \"cost\",\"wastage\",\"hr_workforce\"],\n",
    "    label=\"Domain\"\n",
    ")\n",
    "\n",
    "environment = dbutils.widgets.get(\"environment\")\n",
    "source = dbutils.widgets.get(\"source\")\n",
    "domain = dbutils.widgets.get(\"domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c358bd76-a86b-49d4-ba16-8242d4bcc604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, to_date, concat_ws, last_day, expr, explode, row_number\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "import sys\n",
    "\n",
    "def get_external_location(name: str) -> str:\n",
    "    return (spark.sql(f\"DESCRIBE EXTERNAL LOCATION `{name}`\")\n",
    "             .select(\"url\")\n",
    "             .collect()[0][0]\n",
    "    )\n",
    "\n",
    "bronze_path = get_external_location(f\"{environment}_extloc_bronze\")\n",
    "silver_path = get_external_location(f\"{environment}_extloc_silver\")\n",
    "gold_path = get_external_location(f\"{environment}_extloc_gold\")\n",
    "checkpoint_path = get_external_location(f\"{environment}_extloc_checkpoint\")\n",
    "staging_path = get_external_location(f\"{environment}_extloc_staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0db9580-ee14-45b5-97cd-c74cf1976255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, current_timestamp, max as _max\n",
    "\n",
    "SOURCE_TABLE =\"fq_dev_catalog.bronze.hr_workforce\"\n",
    "VERSION_TABLE = \"fq_dev_catalog.bronze.version_control\"\n",
    "CONSUMER_NAME = \"hr_workforce_silver_trial\"\n",
    "\n",
    "# 1️ Get latest version from source\n",
    "delta_table = DeltaTable.forName(spark, SOURCE_TABLE)\n",
    "\n",
    "latest_version = (\n",
    "    delta_table.history()\n",
    "    .select(_max(\"version\").alias(\"latest_version\"))\n",
    "    .collect()[0][\"latest_version\"]\n",
    ")\n",
    "\n",
    "# 2️ Get last processed version\n",
    "if spark.catalog.tableExists(VERSION_TABLE):\n",
    "    last_processed_version = (\n",
    "        spark.table(VERSION_TABLE)\n",
    "        .filter(col(\"source_table\") == SOURCE_TABLE)\n",
    "        .filter(col(\"consumer_name\") == CONSUMER_NAME)\n",
    "        .agg(_max(\"last_processed_version\").alias(\"last_version\"))\n",
    "        .collect()[0][\"last_version\"]\n",
    "    )\n",
    "else:\n",
    "    last_processed_version = None\n",
    "\n",
    "last_processed_version = last_processed_version if last_processed_version is not None else -1\n",
    "\n",
    "# 3️ Decide whether to process\n",
    "if last_processed_version >= latest_version:\n",
    "    print(\n",
    "        f\"[INFO] No new data to process | \"\n",
    "        f\"Latest version: {latest_version}, \"\n",
    "        f\"Last processed: {last_processed_version}\"\n",
    "    )\n",
    "    df_bronze_workforce_new = None  \n",
    "else:\n",
    "    start_version = last_processed_version + 1\n",
    "    print(\n",
    "        f\"[INFO] Processing versions from {start_version} to {latest_version}\"\n",
    "    )\n",
    "\n",
    "    df_bronze_workforce_new = (\n",
    "        spark.read\n",
    "        .format(\"delta\")\n",
    "        .option(\"startingVersion\", start_version)\n",
    "        .table(SOURCE_TABLE)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c363a40-7f14-4ff0-8270-56e3138fa445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_bronze_workforce_new.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb4fe683-df64-4a25-b70a-c84fc1c490af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import count\n",
    "# df_bronze_workforce_new.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8583101a-f98d-43d0-82ae-e722eba6ec7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_bronze_workforce_new.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c13019f7-ce20-4f72-bfa5-f2e5c81296c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "\n",
    "REJECTED_TABLE = \"fq_dev_catalog.silver.workforce_rejected\"\n",
    "\n",
    "def upsert_rejected(\n",
    "    df,\n",
    "    rejection_type,\n",
    "    rejection_reason,\n",
    "    run_date,\n",
    "    run_id,\n",
    "    rejected_stage=\"SILVER\"\n",
    "):\n",
    "    rejected_df = (\n",
    "        df\n",
    "        .withColumn(\"rejection_type\", lit(rejection_type))\n",
    "        .withColumn(\"rejection_reason\", lit(rejection_reason))\n",
    "        .withColumn(\"rejected_stage\", lit(rejected_stage))\n",
    "        .withColumn(\"run_date\", lit(run_date))\n",
    "        .withColumn(\"run_id\", lit(run_id))\n",
    "        .withColumn(\"rejection_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    target = DeltaTable.forName(spark, REJECTED_TABLE)\n",
    "\n",
    "    (\n",
    "        target.alias(\"t\")\n",
    "        .merge(\n",
    "            rejected_df.alias(\"s\"),\n",
    "            \"\"\"\n",
    "            t.run_date = s.run_date\n",
    "            AND t.business_date = s.business_date\n",
    "            AND t.deployment_name = s.deployment_name\n",
    "            AND t.leave_categories = s.leave_categories\n",
    "            AND t.designation = s.designation\n",
    "            AND t.rejection_reason = s.rejection_reason\n",
    "            \"\"\"\n",
    "        )\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8667f369-aa09-4eb3-a531-3db6d912da7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "store_df = (\n",
    "        spark.read\n",
    "            .table(f\"{environment}_catalog.silver.dim_store\")\n",
    "            .select(\n",
    "            \"deployment_name\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f730900-f022-4071-b643-85895cf92f82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import lit, current_timestamp, col\n",
    "\n",
    "# workforce_rejected_stores = (\n",
    "#     df_silver_workforce.alias(\"b\")\n",
    "#     .join(\n",
    "#         store_df.alias(\"s\"),\n",
    "#         col(\"b.deployment_name\") == col(\"s.deployment_name\"),\n",
    "#         \"left\"\n",
    "#     )\n",
    "#     .filter(col(\"s.deployment_name\").isNull())\n",
    "#     .select(\"b.*\")   # keep only budget columns\n",
    "#     .withColumn(\n",
    "#         \"rejection_reason\",\n",
    "#         lit(\"STORE_NOT_FOUND_IN_MASTER_TABLE_dim_store\")\n",
    "#     )\n",
    "#     .withColumn(\"rejection_ts\", current_timestamp())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4198c752-a4d0-4f1b-975b-d1ee35fb123b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rejected_reference_df = (\n",
    "    df_bronze_workforce_new.alias(\"b\")\n",
    "    .join(\n",
    "        store_df.alias(\"s\"),\n",
    "        col(\"b.deployment_name\") == col(\"s.deployment_name\"),\n",
    "        \"left\"\n",
    "    )\n",
    "    .filter(col(\"s.deployment_name\").isNull())\n",
    "    .select(\"b.*\")\n",
    ")\n",
    "\n",
    "write_rejected(\n",
    "    rejected_reference_df,\n",
    "    rejection_type=\"REFERENCE_VALIDATION\",\n",
    "    rejection_reason=\"STORE_NOT_FOUND_IN_MASTER_TABLE_dim_store\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec3ff17a-acd2-4e3a-8813-240c6f9ca1aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, regexp_extract, count\n",
    "\n",
    "df_silver_base = (\n",
    "    df_bronze_workforce_new\n",
    "    .withColumn(\"rhc_value\", col(\"rhc_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"rc_value\", col(\"rc_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"qcc_value\", col(\"qcc_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"rac_value\", col(\"rac_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"pac_value\", col(\"pac_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"sac_value\", col(\"sac_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"ltm_value\", col(\"ltm_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"tm_value\", col(\"tm_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"crl_value\", col(\"crl_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"trainee_value\", col(\"trainee_value\").cast(\"decimal(12,3)\"))\n",
    "    .withColumn(\"deployment_name\", regexp_extract(col(\"file_path\"), r\"/([^/]+)\\.xlsx$\", 1))\n",
    "    .withColumnRenamed(\"Date\",\"business_date\")\n",
    "    .withColumn(\"source_system\", lit(\"FoodQuest_sharepoint\"))\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5559e4db-cf95-4130-ba5e-9842350d07c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_silver_base.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cf04b6b-c90a-4a64-b84b-245c9e7991e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,element_at, split\n",
    "\n",
    "df_silver_workforce = (\n",
    "    df_silver_base\n",
    "    .select(\n",
    "        col(\"business_date\"),\n",
    "        col(\"leave_categories\"),\n",
    "\n",
    "        col(\"rhc_count\"), col(\"rhc_value\"),\n",
    "        col(\"rc_count\"), col(\"rc_value\"),\n",
    "        col(\"qcc_count\"), col(\"qcc_value\"),\n",
    "        col(\"rac_count\"), col(\"rac_value\"),\n",
    "        col(\"pac_count\"), col(\"pac_value\"),\n",
    "        col(\"sac_count\"), col(\"sac_value\"),\n",
    "        col(\"ltm_count\"), col(\"ltm_value\"),\n",
    "        col(\"tm_count\"), col(\"tm_value\"),\n",
    "        col(\"crl_count\"), col(\"crl_value\"),\n",
    "        col(\"trainee_count\"), col(\"trainee_value\"),\n",
    "        col(\"deployment_name\"),\n",
    "        col(\"ingestion_ts\"),\n",
    "        col(\"file_path\"),\n",
    "        col(\"source_system\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "819d32fd-3067-47ed-b66c-524235a8b791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_silver_workforce.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62b55a0b-d44c-47d4-b7fd-be398c09a56e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769690147050}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_silver_workforce.select(\"deployment_name\").distinct().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46c04e42-2857-404b-8779-d28fb4553943",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_silver_workforce.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf56befb-3743-49b5-90cf-e207ffbdee15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# store_df = (\n",
    "#         spark.read\n",
    "#             .table(f\"{environment}_catalog.silver.dim_store\")\n",
    "#             .select(\n",
    "#             \"deployment_name\"\n",
    "#         )\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f281d311-f811-46e5-9bbd-594a0a642db9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import lit, current_timestamp, col\n",
    "\n",
    "# workforce_rejected_stores = (\n",
    "#     df_silver_workforce.alias(\"b\")\n",
    "#     .join(\n",
    "#         store_df.alias(\"s\"),\n",
    "#         col(\"b.deployment_name\") == col(\"s.deployment_name\"),\n",
    "#         \"left\"\n",
    "#     )\n",
    "#     .filter(col(\"s.deployment_name\").isNull())\n",
    "#     .select(\"b.*\")   # keep only budget columns\n",
    "#     .withColumn(\n",
    "#         \"rejection_reason\",\n",
    "#         lit(\"STORE_NOT_FOUND_IN_MASTER_TABLE_dim_store\")\n",
    "#     )\n",
    "#     .withColumn(\"rejection_ts\", current_timestamp())\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a9e5892-9787-4bf9-9115-75368f205221",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "workforce_rejected_stores.select(\"deployment_name\").distinct().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3303a2c-f31b-4068-9456-e3f2ffb728b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# drop table if exists fq_dev_catalog.silver.workforce_rejected_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e433967b-7a93-48aa-bf2c-c91015cb58d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\"\"\"\n",
    "# CREATE TABLE IF NOT EXISTS fq_dev_catalog.silver.workforce_rejected_stores\n",
    "# USING DELTA\n",
    "# TBLPROPERTIES (delta.enableChangeDataFeed = true, delta.autoOptimize.optimizeWrite = true, delta.autoOptimize.autoCompact = true, delta.columnMapping.mode = 'name')\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1558ef8d-07d7-4f41-aeae-4de699f93b6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "target_table=\"fq_dev_catalog.silver.workforce_rejected_stores\"\n",
    "def write_workforce_rejected_to_silver(df):\n",
    "    query = (\n",
    "            workforce_rejected_stores.write\n",
    "                .format(\"delta\")\n",
    "                .mode(\"overwrite\")\n",
    "                .option(\"mergeSchema\", \"true\")\n",
    "                .saveAsTable(target_table)\n",
    "    )\n",
    "    return query\n",
    "write_workforce_rejected_to_silver(workforce_rejected_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcd43ffd-92c1-4f43-827b-293a9a89561a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select count(\"*\") from fq_dev_catalog.silver.workforce_rejected_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35512765-653c-4abd-887f-f4d595cc4a0c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769508946362}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select distinct deployment_name from fq_dev_catalog.silver.workforce_rejected_stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15537eae-1361-44a1-bbb4-e7701bff90bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Rename once, outside function\n",
    "store_df = store_df.withColumnRenamed(\n",
    "    \"deployment_name\", \"store_deployment_name\"\n",
    ")\n",
    "\n",
    "def create_final_workforce(df, store_df):\n",
    "\n",
    "    df_joined = (\n",
    "        df.join(\n",
    "            store_df,\n",
    "            col(\"deployment_name\") == col(\"store_deployment_name\"),\n",
    "            \"inner\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    df_final = (\n",
    "        df_joined\n",
    "        .select(\n",
    "            col(\"business_date\"),\n",
    "            col(\"leave_categories\"),\n",
    "\n",
    "            col(\"rhc_count\"), col(\"rhc_value\"),\n",
    "            col(\"rc_count\"), col(\"rc_value\"),\n",
    "            col(\"qcc_count\"), col(\"qcc_value\"),\n",
    "            col(\"rac_count\"), col(\"rac_value\"),\n",
    "            col(\"pac_count\"), col(\"pac_value\"),\n",
    "            col(\"sac_count\"), col(\"sac_value\"),\n",
    "            col(\"ltm_count\"), col(\"ltm_value\"),\n",
    "            col(\"tm_count\"), col(\"tm_value\"),\n",
    "            col(\"crl_count\"), col(\"crl_value\"),\n",
    "            col(\"trainee_count\"), col(\"trainee_value\"),\n",
    "\n",
    "            col(\"deployment_name\"),\n",
    "\n",
    "            # metadata\n",
    "            col(\"ingestion_ts\"),\n",
    "            col(\"file_path\"),\n",
    "            col(\"source_system\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "df_final_base = create_final_workforce(\n",
    "    df_silver_workforce,\n",
    "    store_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31887213-0ce7-4fdc-b426-6b36bf66691f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_final_base.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "714c8d31-18b8-485f-83a2-413b8a808ec1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769692045464}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_final_base.select(\"deployment_name\").distinct().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aabcc7f5-cac6-43e6-ae8c-ff673d5dd6ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_final_base.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67f4f0d5-0c6b-423b-8d9c-1ec2bd17bd68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number, last, col\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import date\n",
    "today=date.today()\n",
    "\n",
    "# Window for row numbering (FIXED)\n",
    "w_row = (\n",
    "    Window\n",
    "    .partitionBy(\"deployment_name\") \n",
    "    .orderBy(\"file_path\")            \n",
    ")\n",
    "\n",
    "df = df_final_base.withColumn(\n",
    "    \"row_num\",\n",
    "    row_number().over(w_row)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b790593e-b482-4fd1-8c35-372106983b4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "w_fill = (\n",
    "    Window\n",
    "    .partitionBy(\"deployment_name\")\n",
    "    .orderBy(\"row_num\")\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    ")\n",
    "\n",
    "df_filled = (\n",
    "    df\n",
    "    .withColumn(\n",
    "        \"business_date\",\n",
    "        last(col(\"business_date\"), ignorenulls=True).over(w_fill)\n",
    "    )\n",
    "    \n",
    "    .drop(\"row_num\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7a55385-0845-446f-ab03-fa6b922f3b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_filled.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e483f29-e0b1-43e4-8840-7c9a5c81e619",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_filled.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b28cd0c0-7f77-464a-82ac-6fc941bb61b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_filled.selectExpr(\"max(business_date)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44f950ff-8af1-4fb8-9b1b-9b1a8d533fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_filled.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ddcab0f-2158-4428-9489-8583e4a9cfba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df_schema = df_filled.selectExpr(\n",
    "    \"business_date\",\n",
    "    \"leave_categories\",\n",
    "    \"deployment_name\",\n",
    "    \"file_path\",\n",
    "    \"source_system\",\n",
    "    \"\"\"\n",
    "        stack(\n",
    "            10,\n",
    "            'RHC', rhc_count, rhc_value,\n",
    "            'RC',  rc_count,  rc_value,\n",
    "            'QCC', qcc_count, qcc_value,\n",
    "            'RAC', rac_count, rac_value,\n",
    "            'PAC', pac_count, pac_value,\n",
    "            'SAC', sac_count, sac_value,\n",
    "            'LTM', ltm_count, ltm_value,\n",
    "            'TM',  tm_count,  tm_value,\n",
    "            'CRL', crl_count, crl_value,\n",
    "            'Trainee', trainee_count, trainee_value\n",
    "        ) as (designation, employee_count, employee_cost)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# df_schema.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0c1dbf8-97eb-44ad-8474-1920b2da7692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_schema.filter(col(\"business_date\")==\"2026-12-31\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b90cbb4-d7e2-4ecf-9506-600ec725d411",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import count\n",
    "# df_schema.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0826dabe-f23e-4205-8a55-bfa3e98ab68e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DateType, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import col, trim, when\n",
    "\n",
    "final_df = df_schema.select(\n",
    "    col(\"business_date\").cast(DateType()).alias(\"business_date\"),\n",
    "    \"deployment_name\",\n",
    "    \"leave_categories\",\n",
    "    \"designation\",\n",
    "    \"employee_count\",\n",
    "    \"employee_cost\",\n",
    "    \"file_path\",\n",
    "    \"source_system\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8293d2ef-8dc4-49e9-9a8c-e944b5a6804f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# final_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f46f8303-6162-4298-b7f4-ca2268e1c58a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import count\n",
    "# final_df.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53ca3f9c-ff22-4554-8820-4fb6558bfd76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "final_df_unique = (\n",
    "    final_df\n",
    "    .dropDuplicates(\n",
    "        [\n",
    "            \"business_date\",\n",
    "            \"deployment_name\",\n",
    "            \"leave_categories\",\n",
    "            \"designation\"\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6a02812-94a7-4900-9a00-30350106adbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df_filled = (\n",
    "    final_df_unique\n",
    "    .dropna(\n",
    "        subset=[\n",
    "            \"business_date\",\n",
    "            \"deployment_name\",\n",
    "            \"leave_categories\",\n",
    "            \"designation\"\n",
    "        ]\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a037c02-7ffb-44a2-ba28-c303207ae885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import count\n",
    "# final_df_filled.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b9dbe7b-ce08-4b32-a18a-45708d5fba25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "final_workforce_data = (\n",
    "    final_df_filled\n",
    "    .select(\n",
    "        col(\"business_date\"),\n",
    "        col(\"deployment_name\"),\n",
    "        col(\"leave_categories\").alias(\"leave_category\"),\n",
    "        col(\"designation\"),\n",
    "        col(\"employee_count\"),\n",
    "        col(\"employee_cost\"),\n",
    "        col(\"source_system\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7410836c-1bfc-49b8-bc81-fda845441aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "final_workforce_data = (\n",
    "    final_workforce_data\n",
    "    .withColumn(\"run_date\", lit(today))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01279005-dafd-4dac-9c20-c21b60af123f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# final_workforce_data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "183e8830-e61f-4d2d-a425-ad789b9de823",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": null,
       "filterBlob": "{\"version\":1,\"filterGroups\":[],\"syncTimestamp\":1769582174080}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# final_workforce_data.agg(count(\"*\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2990aed-e7df-44bc-b3d3-6a111d0f0509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# CREATE TABLE IF NOT EXISTS fq_dev_catalog.silver.hr_workforce (\n",
    "#   business_date DATE ,\n",
    "#   deployment_name STRING NOT NULL,\n",
    "#   leave_category STRING NOT NULL,\n",
    "#   designation STRING NOT NULL,\n",
    "#   employee_count LONG ,\n",
    "#   employee_cost DECIMAL(12,3),\n",
    "#   source_system STRING NOT NULL,\n",
    "#   run_date DATE\n",
    "# )\n",
    "# USING DELTA\n",
    "# TBLPROPERTIES (\n",
    "#    delta.enableChangeDataFeed = true,\n",
    "#    delta.autoOptimize.optimizeWrite = true,\n",
    "#    delta.autoOptimize.autoCompact = true,\n",
    "#    delta.columnMapping.mode = 'name'\n",
    "# );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56020a0e-1128-4f4f-b089-c9d7255dbd06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "import sys\n",
    "\n",
    "def upsert_to_silver_batch(\n",
    "    df,\n",
    "    table_name,\n",
    "    business_keys\n",
    "):\n",
    "    try:\n",
    "        # Skip empty DataFrame\n",
    "        if df.isEmpty():\n",
    "            print(\"No data to upsert\")\n",
    "            return\n",
    "\n",
    "        # Load target Delta table\n",
    "        silver_table = DeltaTable.forName(spark, table_name)\n",
    "\n",
    "        # Build merge condition dynamically\n",
    "        merge_condition = \" AND \".join(\n",
    "            [f\"t.{k} = s.{k}\" for k in business_keys]\n",
    "        )\n",
    "\n",
    "        (\n",
    "            silver_table.alias(\"t\")\n",
    "            .merge(\n",
    "                df.alias(\"s\"),\n",
    "                merge_condition\n",
    "            )\n",
    "            .whenMatchedUpdate(set={\n",
    "                \"employee_count\": \"s.employee_count\",\n",
    "                \"employee_cost\": \"s.employee_cost\",\n",
    "                \"source_system\": \"s.source_system\",\n",
    "                \"run_date\": \"s.run_date\"\n",
    "            })\n",
    "            .whenNotMatchedInsert(values={\n",
    "                \"business_date\": \"s.business_date\",\n",
    "                \"deployment_name\":\"s.deployment_name\",\n",
    "                \"leave_category\": \"s.leave_category\", \n",
    "                \"designation\" :\"s.designation\",\n",
    "                \"employee_count\": \"s.employee_count\",\n",
    "                \"employee_cost\": \"s.employee_cost\",\n",
    "                \"source_system\": \"s.source_system\",\n",
    "                \"run_date\": \"s.run_date\"\n",
    "            })\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "        print(\"Batch upsert to silver completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Upsert to Silver failed: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "984519f7-5de8-487f-a6af-f1b9ca78fdf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "silver_table_name = f\"{environment}_catalog.silver.hr_workforce\"\n",
    "\n",
    "business_keys = [\n",
    "        \"business_date\",\n",
    "        \"deployment_name\",\n",
    "        \"leave_category\",\n",
    "        \"designation\"\n",
    "]\n",
    "\n",
    "upsert_to_silver_batch(\n",
    "    final_workforce_data,        \n",
    "    silver_table_name,       \n",
    "    business_keys        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e99931a-425a-46fb-87eb-4ef7cda52a56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\"\"\"\n",
    "# INSERT INTO {VERSION_TABLE} (source_table, consumer_name, last_processed_version, updated_at)\n",
    "# SELECT\n",
    "#   '{SOURCE_TABLE}',\n",
    "#   '{CONSUMER_NAME}',\n",
    "#   {latest_version},\n",
    "#   current_timestamp()\n",
    "# WHERE NOT EXISTS (\n",
    "#   SELECT 1\n",
    "#   FROM {VERSION_TABLE}\n",
    "#   WHERE\n",
    "#     source_table = '{SOURCE_TABLE}'\n",
    "#     AND consumer_name = '{CONSUMER_NAME}'\n",
    "# )\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3654c065-0594-4281-938e-9114638fe03e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\"\"\"\n",
    "# UPDATE {VERSION_TABLE}\n",
    "# SET\n",
    "#   last_processed_version = {latest_version},\n",
    "#   updated_at = current_timestamp()\n",
    "# WHERE\n",
    "#   source_table = '{SOURCE_TABLE}'\n",
    "#   AND consumer_name = '{CONSUMER_NAME}'\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15f7b3ef-3174-46d0-9d9c-0709415d5bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select * from fq_dev_catalog.silver.hr_workforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e7a9c4b-f6ff-47fa-a40a-229ed641fc5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select * from fq_dev_catalog.silver.hr_workforce\n",
    "# where deployment_name = \"ALBAIK - SQ DB27 - AL TALLAH - 1005028\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c52b993-9173-43fb-a353-bf14af0b3397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select count(\"*\") from fq_dev_catalog.silver.hr_workforce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57c311bb-7217-4aeb-a12b-dd0ad8663ad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# select distinct deployment_name from fq_dev_catalog.silver.hr_workforce"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5528722754594558,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "hr_workforce_silver_trial)",
   "widgets": {
    "domain": {
     "currentValue": "hr_workforce",
     "nuid": "0b3407a8-0afa-4f2e-80f5-99416f4fa5b2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "hr_workforce",
      "label": "Domain",
      "name": "domain",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "discount",
        "sales",
        "cost",
        "wastage",
        "hr_workforce"
       ],
       "fixedDomain": false,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "combobox",
      "defaultValue": "hr_workforce",
      "label": "Domain",
      "name": "domain",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "discount",
        "sales",
        "cost",
        "wastage",
        "hr_workforce"
       ]
      }
     }
    },
    "environment": {
     "currentValue": "fq_dev",
     "nuid": "f0691973-c240-4e93-90f4-33a0bf65115a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "fq_dev",
      "label": "Select environment",
      "name": "environment",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "fq_dev",
        "fq_test",
        "fq_prod"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "fq_dev",
      "label": "Select environment",
      "name": "environment",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "fq_dev",
        "fq_test",
        "fq_prod"
       ]
      }
     }
    },
    "source": {
     "currentValue": "foodquest_sharepoint",
     "nuid": "bee575ba-4935-4b52-a424-bb851c4cd307",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "foodquest_sharepoint",
      "label": "Source",
      "name": "source",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "posist",
        "netsuite",
        "other",
        "excel_sheet",
        "foodquest_sharepoint"
       ],
       "fixedDomain": false,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "combobox",
      "defaultValue": "foodquest_sharepoint",
      "label": "Source",
      "name": "source",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "posist",
        "netsuite",
        "other",
        "excel_sheet",
        "foodquest_sharepoint"
       ]
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
